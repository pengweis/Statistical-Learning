
library(MASS) # Data source
library(car)  # vif among other things
library(knitr) # kable light weight table generator 
library(glmnet)

data(Boston) # load data


lm.crim <- lm(crim ~ ., data = Boston)
lm.crim.summary <- summary(lm.crim)

lm.crim.summary

#lm.crim.coef = t(t(lm.crim.summary$coefficients)) # Save off results

#look at VIF to see if any multicolinearity exists

#lm.crim.vif = t(t(vif(lm.crim)))
#colnames(lm.crim.vif) = "VIF"
#rownames(lm.crim.vif)[3] = "chas1" 

#fullLMresults = merge(lm.crim.vif,lm.crim.coef, by = 0, all = TRUE)
#rownames(fullLMresults) = fullLMresults$Row.names
#fullLMresults = fullLMresults[-1]
#kable(fullLMresults, format = 'pipe')

## Ridge Regression

# Create our x matrix
x = model.matrix(crim~.,Boston)[,-1]
y = Boston$crim # Create our response vector (y)

set.seed(8)
maxNumPred = 13
# Get Training and Testing Data Set
train = sample(1:nrow(x), 3*nrow(x)/5) # wanted ~300 obs for 10-fold CV, so each fold has ~30 obs.
test = -(train)
y.test = y[test]

# Fit ridge regression on the training set
grid=10^seq(10, -2, length=100)
ridge.mod = glmnet(x[train,], y[train], alpha=0, lambda=grid, thresh=1e-12)

# Perform k-fold cross validation on all the data to determine best lambda value
ridge.cv.out = cv.glmnet(x[train,], y[train], alpha=0) # this does 10-fold cv by default, appropriate with 500 obs
ridge.bestlam=ridge.cv.out$lambda.min

# MSE associated with value of lambda that results in smallest cv-error
ridge.pred = predict(ridge.mod, s=ridge.bestlam, newx=x[test,])
ridge.MSE = mean((ridge.pred - y.test)^2)

# Now refit ridge regression on full data set, using the value of lambda
# selected by cross-validation
ridge.modF = glmnet(x, y, alpha=0, lambda=grid)
ridge.coef=predict(ridge.modF,type="coefficients",s=ridge.bestlam)[1:maxNumPred,]
# Save off Results
ridgeModelResults = data.frame(as.list(ridge.coef))
ridgeModelResults$'Test MSE' = ridge.MSE
ridgeModelResults$BestLambda = ridge.bestlam
row.names(ridgeModelResults) = 'RidgeRegression'
# Rearrange variables 
ridgeModelResults = ridgeModelResults[,c(which(colnames(ridgeModelResults)=="BestLambda"), which(colnames(ridgeModelResults)!="BestLambda"))]
ridgeModelResults = ridgeModelResults[,c(which(colnames(ridgeModelResults)=="Test MSE"),which(colnames(ridgeModelResults)!="Test MSE"))]
ridgeModelResults = t(ridgeModelResults) # transpose for easier table display

# display results in table
kable(ridgeModelResults, format = 'markdown')


###Lasso
set.seed(1)
# Fit lasso on the training set (same one used as ridge)
grid=10^seq(10, -2, length=100) # using same grid as before (optional: could use new grid)
lasso.mod = glmnet(x[train,], y[train], alpha=1, lambda=grid, thresh=1e-12)

# Create lasso model, perform k-fold CV, and get best lambda and lowest MSE
lasso.cv.out= cv.glmnet(x[train,], y[train], alpha=1)
lasso.bestlam=lasso.cv.out$lambda.min

lasso.pred = predict(lasso.mod, s=lasso.bestlam, newx=x[test,])
lasso.MSE = mean((lasso.pred - y.test)^2) # test set MSE

# Now refit lasso on full data set, using the value of lambda
# selected by cross-validation
lasso.modF = glmnet(x, y, alpha=1, lambda=grid)
lasso.coef = predict(lasso.modF, type="coefficients", s=lasso.bestlam)[1:maxNumPred,]

# Get coefficients and save off results
lasso.coef = data.frame(as.list(lasso.coef))
lassoModelResults = data.frame(as.list(lasso.coef))
lassoModelResults$'Test MSE' = lasso.MSE
lassoModelResults$BestLambda = lasso.bestlam
row.names(lassoModelResults) = 'Lasso'
# Rearrange variables
lassoModelResults = lassoModelResults[,c(which(colnames(lassoModelResults)=="BestLambda"), which(colnames(lassoModelResults)!="BestLambda"))]
lassoModelResults = lassoModelResults[,c(which(colnames(lassoModelResults)=="Test MSE"),which(colnames(lassoModelResults)!="Test MSE"))]
lassoModelResults = t(lassoModelResults) # transpose for easier table display

# display results in table
kable(lassoModelResults, format = 'markdown')



